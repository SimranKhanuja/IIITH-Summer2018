{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create chunks in English which are consistent with the chunks output by the Hindi parser.\n",
    "Hindi Parser :- LTRC Shallow Hindi Parser, IIIT Hyderabad\n",
    "English Parser :- Stanford Parser\n",
    "\n",
    "#### Chunk and head tag rules in Hindi Parser-\n",
    "^NP    : NN.*|PRP\n",
    "^VG.*  : VM\n",
    "^JJP   : JJ|QF|QC|QO\n",
    "^RBP   : RB\n",
    "^FRAGP : PSP|RP\n",
    "^NEGP  : NEG\n",
    "^CCP   : CC\n",
    "^BLK   : SYM\n",
    "\n",
    "#### Analogies between Hindi and English(Penn Treebank - used by stanford parser) Tags-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary of phrase tags with it's corresponding heads according to the rules of the Hindi parser \n",
    "#to create chunks in English which are consistent with the chunks output by the Hindi parser.\n",
    "from nltk.tree import ParentedTree\n",
    "eng=open('ParsedLowEngWPOSingle.txt',encoding='utf-8')\n",
    "content = eng.read().split(\"\\n\")\n",
    "allsent = []\n",
    "allpos = []\n",
    "   \n",
    "list_of_phrase_tags=['VP','NP','ADJP','ADVP','PP']                #as in hindi parser\n",
    "heads = {\"NP\":[\"NNS\",\"NNP\",'PRP','NN','NNPS'],               #corresponding heads for the phrases\n",
    "             \"VP\":['VBP','VBZ','VBG','VBD','VBN','VB'],\n",
    "             \"ADJP\":['JJR','JJS','JJ','VBN'],\n",
    "             \"ADVP\":['RB','RBR'],\n",
    "             \"CC\" : ['CC'],\n",
    "             \"PP\" : [\"IN\"]\n",
    "             }\n",
    "check = ['RB','RBR','JJ','JJR','JJS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ParentedTree.read(): expected '(' but got 'end-of-string'\n            at index 0.\n                \"\"\n                 ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-200224f3606a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mptree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParentedTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mleaf_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mptree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m##ptree.pretty_print()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36mfromstring\u001b[1;34m(cls, s, brackets, read_node, read_leaf, node_pattern, leaf_pattern, remove_empty_top_bracketing)\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end-of-string'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end-of-string'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_parse_error\u001b[1;34m(cls, s, match, expecting)\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\n%s\"%s\"\\n%s^'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;31m#////////////////////////////////////////////////////////////\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ParentedTree.read(): expected '(' but got 'end-of-string'\n            at index 0.\n                \"\"\n                 ^"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "for q in content:\n",
    "    ptree = ParentedTree.fromstring(q)\n",
    "    leaf_values = ptree.leaves()\n",
    "    ##ptree.pretty_print()\n",
    "    ls = []\n",
    "    pos={}\n",
    "    for x in ptree.leaves():\n",
    "        i=-2\n",
    "        leaf_index = leaf_values.index(x)\n",
    "        tree_location = ptree.leaf_treeposition(leaf_index)\n",
    "        y=str(ptree[tree_location[:i]])\n",
    "        p=str(ptree[tree_location[:-1]])\n",
    "        indexp = p.find(\" \")\n",
    "        indexnp = p.find(\"\\n\")\n",
    "        if(indexnp<indexp and indexnp!=(-1)):\n",
    "            indexp = indexnp\n",
    "        pos.update({x:p[1:indexp]})\n",
    "        while(i>-(ptree.height())):\n",
    "            indexy = y.find(\" \")\n",
    "            indexny = y.find(\"\\n\")\n",
    "            if(indexny<indexy and indexny!=(-1)):\n",
    "                indexy = indexny\n",
    "            if(y[1:indexy] in list_of_phrase_tags):\n",
    "                ls.append([x, y[1:indexy]])\n",
    "                break\n",
    "            else:\n",
    "                i=i-1\n",
    "                y=str(ptree[tree_location[:i]])\n",
    "    tag = ls[0][1]\n",
    "    chunk=[]\n",
    "    st = []\n",
    "    i=0\n",
    "    for x in ls:\n",
    "        y = x[0]\n",
    "        if(pos.get(y)=='CC'):\n",
    "            if(flag):\n",
    "                chunk.append([tag,st])\n",
    "                st=[]\n",
    "            st.append(y)\n",
    "            tag=\"CC\"\n",
    "            chunk.append([tag,st])\n",
    "            st = []\n",
    "            flag=False\n",
    "        elif (pos.get(y) in heads.get(x[1])):\n",
    "            st.append(y)\n",
    "            tag=x[1]\n",
    "            chunk.append([tag,st])\n",
    "            st =[]\n",
    "            flag=False\n",
    "        elif x[1]==tag:\n",
    "            flag=True\n",
    "            st.append(y)\n",
    "        else:  \n",
    "            if(flag):\n",
    "                chunk.append([tag,st])\n",
    "            tag = x[1]\n",
    "            st =[]\n",
    "            st.append(y)\n",
    "            flag=True\n",
    "    if(len(st)>0):\n",
    "        chunk.append([tag,st])\n",
    "    newchunk = []\n",
    "    for (i,x) in enumerate(chunk):\n",
    "        if(i<len(chunk)-1):\n",
    "            if i>0 and x[0]=='PP' and chunk[i+1][0]=='NP' and (chunk[i-1][0]=='NP' and pos.get(chunk[i-1][1][0]) in check):\n",
    "                chunk[i+1][1] = chunk[i-1][1] + x[1] + chunk[i+1][1]\n",
    "                newchunk.pop()\n",
    "                #newchunk.append(chunk[i+1])\n",
    "            elif x[0]=='PP' and (chunk[i+1][0]=='NP' or chunk[i+1][0]=='VP') :\n",
    "                chunk[i+1][1] = x[1] + chunk[i+1][1]\n",
    "            else:\n",
    "                newchunk.append(x)\n",
    "        else:\n",
    "            newchunk.append(x)\n",
    "    for x in newchunk:\n",
    "        for y in heads.keys():\n",
    "            if x[0]==y:\n",
    "                l = heads.get(y)\n",
    "                for z in x[1]:\n",
    "                    if pos.get(z) in l:\n",
    "                        x[1].append(z)\n",
    "                        break\n",
    "    allsent.append(newchunk)\n",
    "    allpos.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in allsent:\n",
    "    for y in x:\n",
    "        if len(y[1])==1:\n",
    "            y[1].append(y[1][0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = open('SampleNewAllFinal','w',encoding='utf-8')\n",
    "for (j,i) in enumerate(allsent):\n",
    "    en.write(\"SentenceID:\" + str(j+1))\n",
    "    en.write(\"\\n\")\n",
    "    for x in i:\n",
    "        en.write('*' + \"\\t\" + x[0])\n",
    "        en.write(\"\\t\")\n",
    "        if(len(x[1])>0):\n",
    "            en.write(x[1][-1])\n",
    "            en.write(\"\\n\")\n",
    "            for y in x[1][:len(x[1])-1]:\n",
    "                en.write(\"@\")\n",
    "                en.write(\"\\t\")\n",
    "                en.write(allpos[j].get(y))\n",
    "                en.write(\"\\t\")\n",
    "                en.write(y)\n",
    "                en.write(\"\\n\")\n",
    "    en.write(\"#\")\n",
    "    en.write(\"\\n\")\n",
    "en.close()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ROOT              \n",
      "                  |                 \n",
      "                  S                \n",
      "               ___|______________   \n",
      "              VP                 | \n",
      "   ___________|___               |  \n",
      "  |               NP             | \n",
      "  |      _________|____          |  \n",
      "  |     |              PP        | \n",
      "  |     |          ____|____     |  \n",
      "  |     NP        |         NP   | \n",
      "  |     |         |         |    |  \n",
      "  VB    RB        IN        NN   . \n",
      "  |     |         |         |    |  \n",
      "drink plenty      of      water  . \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47008"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptree = ParentedTree.fromstring(content[8])\n",
    "ptree.pretty_print()\n",
    "len(allsent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
